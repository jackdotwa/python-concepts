{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing over Pandas Dataframe Columns\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Objective:\n",
    "Iterate over pandas dataframe and perform column-wise operations in separate processes that honour shared _write-on-copy_ (due to _fork()_) memory\n",
    "\n",
    "#### Steps:\n",
    "  * Monitor used and available memory\n",
    "  * Allocate large dataframe\n",
    "  * Do row counts in multiple processes on columns of that dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System memory checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 55.8% free: 5.25GB\n"
     ]
    }
   ],
   "source": [
    "print('used: {}% free: {:.2f}GB'.format(psutil.virtual_memory().percent, float(psutil.virtual_memory().free)/1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocation of a reasonably large frame (for `cols=6` and `rows=10^8` this results in `4.47GB` of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47GB\n"
     ]
    }
   ],
   "source": [
    "cols = 6\n",
    "columns = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "rows = 10**8\n",
    "df = pd.DataFrame(np.random.randn(rows,cols), columns=columns[0:cols])\n",
    "print('{0:.2f}GB'.format(float(df.memory_usage(index=True).sum())/1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 85.1% free: 0.65GB\n"
     ]
    }
   ],
   "source": [
    "# Another memory check-in\n",
    "print('used: {}% free: {:.2f}GB'.format(psutil.virtual_memory().percent, float(psutil.virtual_memory().free)/1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform multiprocessing across each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "def parallelise_cols(func, df, num_processes=None):\n",
    "    if num_processes==None:\n",
    "        num_processes = min(df.shape[1], cpu_count())\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        # we need a sequence of columns to pass pool.map\n",
    "        #seq = [df[col_name] for col_name in df.columns]\n",
    "        #l = [1,2,3,4,5,6,7,8,9,10]\n",
    "        # pool.map returns results as a list\n",
    "        results_list = pool.map(func, df.iteritems())\n",
    "        # return list of processed columns, concatenated together as a new dataframe\n",
    "        #return pd.concat(results_list, axis=1)\n",
    "\n",
    "def action(data):\n",
    "    print('name: {}; row.count: {}; used: {}% free: {:.2f}GB'.format(data[0], \n",
    "                                                                     len(data[1].index)\n",
    "                                                                     psutil.virtual_memory().percent, \n",
    "                                                                     float(psutil.virtual_memory().free)/1024**3))\n",
    "    time.sleep(2)\n",
    "    print('done sleeping {}'.format(multiprocessing.current_process()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: a; row.count: 100000000; used: 94.3% free: 0.86GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-1, started daemon)>\n",
      "name: b; row.count: 100000000; used: 92.5% free: 1.14GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-2, started daemon)>\n",
      "name: c; row.count: 100000000; used: 94.4% free: 0.85GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-1, started daemon)>\n",
      "name: d; row.count: 100000000; used: 90.4% free: 1.44GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-2, started daemon)>\n",
      "name: e; row.count: 100000000; used: 90.5% free: 1.40GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-1, started daemon)>\n",
      "name: f; row.count: 100000000; used: 84.0% free: 2.38GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-2, started daemon)>\n"
     ]
    }
   ],
   "source": [
    "parallelise_cols(action, df, num_processes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: a; row.count: 100000000; used: 85.3% free: 2.05GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-7, started daemon)>\n",
      "name: b; row.count: 100000000; used: 86.5% free: 1.86GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-8, started daemon)>\n",
      "name: c; row.count: 100000000; used: 87.3% free: 1.74GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-9, started daemon)>\n",
      "name: d; row.count: 100000000; used: 84.1% free: 2.22GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-10, started daemon)>\n",
      "name: e; row.count: 100000000; used: 86.3% free: 1.88GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-7, started daemon)>\n",
      "name: f; row.count: 100000000; used: 79.8% free: 2.86GB\n",
      "done sleeping <ForkProcess(ForkPoolWorker-8, started daemon)>\n"
     ]
    }
   ],
   "source": [
    "parallelise_cols(action, df, num_processes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfauditor",
   "language": "python",
   "name": "dfauditor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
